- Generative AI is a branch of AI to generate new content; 
  - often natural language dialogs, 
  - but also images, video, code, and other formats.
- Generative AI models encapsulate semantic relationships between language elements 
  - i.e. models "know" how words relate to one another
  - and that's what enables them to generate a meaningful sequence of text.
- large language models (LLMs) and small language models (SLMs)
  - LLMs are very powerful and generalize well, but can be more costly to train and use. 
  - SLMs are more focused on specific topic areas, and usually cost less.
- uses of generative AI:
  - chatbots and AI agents to assist human users. 
  - create new documents or other content
  - Automate translation of text between languages.
  - Summarize or explain complex documents.
  - Comparing multiple text sources for semantic similarity.
  - Generating new natural language.
  - Determining sentiment or otherwise classifying natural language text.
-  can combine computer vision and language models to create 
  - a multi-modal model that combines computer vision and generative AI capabilities.
- Transformers
  - Transformer models
    - trained with large volumes of text(natural language text) sourced from the internet or other public sources of text.
    - enabling them to represent the semantic relationships between words and
    - use those relationships to determine probable sequences of text that make sense.
  - Transformer model architecture
    - encoder block
      - creates semantic representations of the training vocabulary.
    - decoder block
      - generates new language sequences.
  - Process
    - train with a large volume of natural language text
    - sequences of text are broken down into tokens
      - encoder block processes these token sequences using a technique called attention 
        - to determine relationships between tokens
    - output from the encoder is a collection of vectors (multivalued numeric arrays)
      - each element of the vector represents a semantic attribute of the tokens. 
      - These vectors are referred to as embeddings.
    - decoder block works on a new sequence of text tokens
      - uses the embeddings generated by the encoder to generate an appropriate natural language output.
    - e.g.
      - input sequence like "When my dog was"
      - predict an appropriate completion of the sentence, such as "a puppy".
  - Models
    - Bidirectional Encoder Representations from Transformers (BERT) model developed by Google
      - to support their search engine uses only the encoder block,
    - Generative Pretrained Transformer (GPT) model developed by OpenAI
      - uses only the decoder block.
- Tokenization
  - decompose the training text into tokens
  - Embeddings
    - contextual vectors
    - multivalued numeric representations of information
    - Vectors represent lines in multidimensional space
    - describing direction and distance along multiple axes
      - called amplitude and magnitude
    - elements in an embedding vector for a token as representing steps along a path in multidimensional space
    - cosine similarity
      - used to determine if two vectors have similar directions
      - regardless of distance
      - represent semantically linked words
    - Attention
      - attention layers
        - examine a sequence of text tokens and
        - try to quantify the strength of the relationships between them.
        - self-attention involves considering how other tokens around one particular token influence that token's meaning.
        - In encoder, each token is carefully examined in context
        - vector values are based on the relationship between the token
        - same word might have multiple embeddings
          - the bark of a tree
          - I heard a dog bark
        - decoder block
          - attention layers are used to predict the next token in a sequence
          - consider which of the tokens are the most influential when considering what the next token should be.
      - multi-head attention
        - uses different elements of the embeddings to calculate multiple attention scores.
        - building the output one token at a time.
    - Steps:
    - A sequence of token embeddings is fed into the attention layer. Each token is represented as a vector of numeric values.
    - The goal in a decoder is to predict the next token in the sequence, which will also be a vector that aligns to an embedding in the modelâ€™s vocabulary.
    - The attention layer evaluates the sequence so far and assigns weights to each token to represent their relative influence on the next token.
    - The weights can be used to compute a new vector for the next token with an attention score. Multi-head attention uses different elements in the embeddings to calculate multiple alternative tokens.
    - A fully connected neural network uses the scores in the calculated vectors to predict the most probable token from the entire vocabulary.
    - The predicted output is appended to the sequence so far, which is used as the input for the next iteration.
- generative AI
  - Artificial Intelligence (AI) imitates human behavior by using machine learning to interact with the environment and execute tasks without explicit directions on what to output.
  - category of capabilities within AI that create original conten
  - capabilities include taking in natural language input, and returning appropriate responses in a variety of formats such as natural language, images, code, and more.
  - Image generation
  - Code generation
  - applications
    - chat-based assistants
    - e.g. Microsoft Copilot
    - utilize language modelsutilize language models
  - utilize language models
  - also executes programmable task
    - filing taxes or coordinating shipping arrangements
    - called as agents
      - can respond to user input or assess situations autonomously
      - and take appropriate actions. 
  - Categories
    - ready-to-use applications
    - extendable applications
      - extend using your own data
      - to better support specific business processes or tasks
      - e.g. Microsoft Copilot 
        - ready to use and extendable
    - applications to build from the foundation
      - build your own assistants and assistants with agentic capabilities starting from a language model
  - Process
    - tokenization
      - turning words into tokens, then to numbers.
    - word embeddings
      - define the semantic relationship between words.
      - represent words in a vector space
      - self-supervised learning
- publicly available models
  - Hugging Face
- proprietary
  - Azure
    - foundation models in the Azure AI Foundry model catalog
      - pretrained on large texts
      - can be fine-tuned for specific tasks with a relatively small dataset.
- Foundation models can be used for various tasks, including:
  - Text classification
  - Token classification
  - Question answering
  - Summarization
  - Translation
- LLM
  - have many billions (even trillions) of parameters (weights that can be applied to vector embeddings to calculate predicted token sequences).
  - Able to exhibit comprehensive language generation capabilities in a wide range of conversational contexts.
  - difficult to deploy locally on devices and computers.
- Prompt
  - specific goal
  - source of information
  - context for appropriateness and relevance
  - clear expectations for the response
  - Iterate based on previous prompts and responses to refine the result
- Internal prompt augmentation by AI
  - system message
    - conditions and constraints
    - conversation history for the current session
      - including past prompts and responses
      - to maintain the context of the conversation
- Retrieval-Augmented Generation (RAG)
  - RAG augments a language model by connecting it to an organization's proprietary database. 
- Fine-tuning
  - taking a pre-trained model and further training it on a smaller, task-specific dataset 
  - to make it more suitable for a particular application.
  - adapting models to domain-specific requirements
- Security and Governance Controls
  - needed to manage access, authentication, and data usage.
  - to prevent the publication of incorrect or unauthorized information.
- Metrics to measure response quality
  - Performance and quality evaluators: 
    - assess the accuracy, groundedness, and relevance of generated content.
  - Risk and safety evaluators: 
  - assess potential risks associated with AI-generated content to safeguard against content risks. 
  - This includes evaluating an AI system's predisposition towards generating harmful or inappropriate content.
  - Custom evaluators: 
    - industry-specific metrics to meet specific needs and goals.
- Azure AI Agent Service
  - frameworks like AutoGen and Semantic Kernel 
    - to build comprehensive AI agent solutions.
- Prompt Flow SDK
  - used to implement orchestration logic to manage prompt interactions with generative AI models.
- responsible generative AI
  - four stages
    - Identify potential harms that are relevant to your planned solution.
    - Measure the presence of these harms in the outputs generated by your solution.
    - Mitigate the harms at multiple layers in your solution to minimize their presence and impact, and 
      - ensure transparent communication about potential risks to users.
    - Operate the solution responsibly by defining and following a deployment and operational readiness plan.
  or
    - Identify potential harms
      - offensive, pejorative, or discriminatory.
      - factual inaccuracies. 
      - illegal or unethical behavior or practices.
    - Prioritize identified harms
      - e.g. inaccurate cooking times
        - resulting in undercooked food that may cause illness.
      - recipe for a lethal poison
    - Test and verify the prioritized harms
      - red team testing
        - testers deliberately probes the solution for weaknesses and 
        - attempts to produce harmful results.
    - Document and share the verified harms
- Mitigation of potential harms at each layer:
  - Model
  - Safety System
    - abuse detection algorithms
      - through high volumes of automated requests from a bot
    - alert notifications
      - fast response to potential system abuse or harmful behavior
  - Metaprompt and grounding
  - User experience
- compliance reviews 
  - Legal
  - Privacy
  - Security
  - Accessibility
- Release and operate the solution
  - Devise a phased delivery plan that enables you to release the solution initially to restricted group of users. This approach enables you to gather feedback and identify problems before releasing to a wider audience.
  - Create an incident response plan that includes estimates of the time taken to respond to unanticipated incidents.
  - Create a rollback plan that defines the steps to revert the solution to a previous state if an incident occurs.
  - Implement the capability to immediately block harmful system responses when they're discovered.
  - Implement a capability to block specific users, applications, or client IP addresses in the event of system misuse.
  - Implement a way for users to provide feedback and report issues. In particular, enable users to report generated content as "inaccurate", "incomplete", "harmful", "offensive", or otherwise problematic.
  - Track telemetry data that enables you to determine user satisfaction and identify functional gaps or usability challenges. Telemetry collected should comply with privacy laws and your own organization's policies and commitments to user privacy.
- AI agent development options
  - Azure AI Agent Service
    - in Azure AI Foundry
    - visual agent development experience
    - code-first development experience
    - 
  - OpenAI Assistants API
    - can only be used with OpenAI models. 
  - Semantic Kernel
    - lightweight, open-source development kit
    - build AI agents and orchestrate multi-agent solutions
  - AutoGen
    - open-source framework for developing agents rapidly
    - useful as a research and ideation tool when experimenting with agents.
  - Microsoft 365 Agents SDK
    - self-hosted agents
    - can be delivered through channels like Slack or Messenger.
  - Microsoft Copilot Studio
    - low-code development environment
    - visual design interface
    - for little or no professional software development experienced
  - Copilot Studio agent builder in Microsoft 365 Copilot
    - for Business users
- Components of an agent
  - Model
    - OpenAI models
    - Azure AI Foundry model catalog
  - Knowledge
    - data sources
    - Internet search results
      - Microsoft Bing
      - Azure AI Search index
      - own data and documents
  - Tools
    - knowledge in Azure AI Search and Bing
    - Azure Functions
